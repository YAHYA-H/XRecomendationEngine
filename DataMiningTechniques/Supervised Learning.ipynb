{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPERVISED LEARNING\n",
    "```Supervised learning is a class of ML algorithms that takes in a series of vectors and their corresponding output as input, and produces an inferred function that can be used to map new example.```\n",
    "\n",
    "\n",
    "```_Supervised learning can be classified into two types: REGRESSION & CLASSIFICATION__```\n",
    "\n",
    "``` A classification problem has a discrete set of values as the target variable( for instance , a like & dislike)  whereas```\n",
    "```A regression problem has a continous value as its target( for instance , an average rating between one and five)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` It's the simplest ML algorithms```\n",
    "```incase of classification, it assign a class to a particular data points by a majority vote of k nearest neighbours, in other words,the data points is assigned the class that is the most common among its k-nearest neighbours```\n",
    "``in regression computes the average values for the largest variables based on K-nearest neighbours```\n",
    "\n",
    "\n",
    "```KNN is non-parametric & lazy in nature. This means that KNN does not make any underlying assumption about the distribution of the data.```\n",
    "```In other words , the model is determined by the data & the latter means that KNN undergoes virtually no training. It computes the K-nearest  neighbours of a particular points in prediction phase.```\n",
    "``This mean that the K-NN model needs to have access to the training data at all times and cannot discard it during prediction like its sister algorithms.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# url & names\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "\n",
    "#Load the Iris dataset into pandas Dataframe\n",
    "iris = pd.read_csv(url,  names=names)\n",
    "\n",
    "# Display iris head\n",
    "iris.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "\n",
    "# split our iris into attributes & labels\n",
    "X = iris.iloc[:, :-1]\n",
    "y = iris.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to test & train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y , test_size=0.20) #80% train 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling so that all of them are  uniformly evaluated\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training & predicting\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# classify\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on our test data\n",
    "y_predict = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  0 10]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         5\n",
      "Iris-versicolor       1.00      0.93      0.97        15\n",
      " Iris-virginica       0.91      1.00      0.95        10\n",
      "\n",
      "      micro avg       0.97      0.97      0.97        30\n",
      "      macro avg       0.97      0.98      0.97        30\n",
      "   weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the algorithms\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector machine\n",
    "\n",
    "```-classification algorithms that takes in an n-dimensional dataset as input and constructs an (n-1) dimensional hyperplane in such a way that there is maximum separation of classess```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ENSEMBLING \n",
    "``` THE MAIN IDEA BEHIND ENSEMBLING IS THAT THE PREDICTIVE POWER OF MULTIPLE ALGORITHMS IN MUCH GREATER THAN A SINGLE ALGORITHM. --Decision trees are the most common base of algorithms used when building ensembling model```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bagging & Random Forests. (short for bootstrap aggregating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like most other ensembling methods, it averages over a large number of base prediction\n",
    "# of base classification & averages their results in deliver its final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like random forest, boosting models build a baseline model using a subset of samples and\n",
    "# features . However, while building the next learners, the boosting model tries to rectify\n",
    "# the mistakes that the previous learners made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the dataset into the features dataframe & athe target class series\n",
    "X, y = iris.drop('class', axis=1), iris['class']\n",
    "\n",
    "# split the data into training & test datasets\n",
    "# we will train on 75% of the data  and assess our perfomance on 25% of the data\n",
    "\n",
    "# import the splitting fucntion\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=0)\n",
    "\n",
    "# import the Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Apply Gradient Boosting to the training data\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# compute the accuracy on the test set\n",
    "gbc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_importance_instance_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-ff97716739f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sepal_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sepal_width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'petal_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'petal_width'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_importance_instance_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_importance_instance_' is not defined"
     ]
    }
   ],
   "source": [
    "# Display a bar plot of feature importance\n",
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(x=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], y=feature_importance_instance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
